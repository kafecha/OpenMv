



## 初始化

- sensor.reset（） 初始化感光元件

## 设置彩色／黑白

- sensor.set_pixformat（） 设置像素模式。
  - 传感器。GRAYSCALE： 灰度，每个像素8bit。
  - 传感器。RGB565： 彩色，每个像素16bit。

## 设置图像大小

- sensor.set_framesize（） 设置图像的大小
  - 传感器。QQCIF：88x72
  - 传感器。QCIF：176x144
  - 传感器。CIF：352x288
  - 传感器。QQSIF：88x60
  - 传感器。QSIF：176x120
  - 传感器。SIF：352x240
  - 传感器。QQQQVGA：40x30
  - 传感器。QQQVGA：80x60
  - 传感器。QQVGA：160x120
  - 传感器。QVGA：320x240
  - 传感器。显卡：640x480
  - 传感器。HQQQVGA：80x40
  - 传感器。HQQVGA：160x80
  - 传感器。HQVGA：240x160
  - 传感器。B64X32： 64x32 （用于帧差异 image.find_displacement（））
  - 传感器。B64X64： 64x64 用于帧差异 image.find_displacement（））
  - 传感器。B128X64：128x64 （用于帧差异 image.find_displacement（））
  - 传感器。B128X128：128x128 （用于帧差异 image.find_displacement（））
  - 传感器。LCD： 128x160 （用于LCD扩展板）
  - 传感器。QQVGA2： 128x160 （用于LCD扩展板）
  - 传感器。WVGA： 720x480 （用于 MT9V034）
  - 传感器。WVGA2：752x480 （用于 MT9V034）
  - 传感器。SVGA： 800x600 （仅用于 OV5640 感光元件）
  - 传感器。XGA：1024x768 （仅用于 OV5640 感光元件）
  - 传感器。SXGA：1280x1024 （仅用于 OV5640 感光元件）
  - 传感器。UXGA：1600x1200 （仅用于 OV5640 感光元件）
  - 传感器。高清：1280x720 （仅用于 OV5640 感光元件）
  - 传感器。FHD：1920x1080 （仅用于 OV5640 感光元件）
  - 传感器。QHD：2560x1440 （仅用于 OV5640 感光元件）
  - 传感器。QXGA： 2048x1536 （仅用于 OV5640 感光元件）
  - 传感器。WQXGA：2560x1600 （仅用于 OV5640 感光元件）
  - 传感器。WQXGA2： 2592x1944 （仅用于 OV5640 感光元件）

## 跳过一些帧

- sensor.skip_frames（n=10） 跳过n张照片，在更改设置后，跳过一些帧，等待感光元件变稳定。

## 获取一张图像

- sensor.snapshot（） 拍摄一张照片，返回一个image对象。

```python


import sensor  # 导入 OpenMV 的 sensor 库，用于与摄像头交互
import time  # 导入 time 库，用于计时
import math  # 导入 math 库，用于数学计算，特别是角度转换
from pyb import UART
import ustruct

# 摄像头初始化设置
sensor.reset()  # 重置摄像头模块，确保初始化清晰
sensor.set_pixformat(sensor.RGB565)  # 设置图像像素格式为 RGB565 格式，适合色彩处理
sensor.set_framesize(sensor.QQVGA)  # 设置图像分辨率为 QVGA (320x240)，分辨率越高，图像质量越好，但处理速度可能会较慢


# *************************** 如果不需要镜像就注释掉以下代码 **************************
# 摄像头的镜像和翻转操作，根据摄像头模块的安装方向决定是否需要
sensor.set_vflip(True)  # 设置垂直翻转。如果摄像头安装方向需要翻转，启用此选项
sensor.set_hmirror(True)  # 设置水平翻转。如果摄像头安装方向需要翻转，启用此选项
# *************************** 如果不需要镜像就注释掉以上代码 **************************


sensor.skip_frames(time=2000)  # 跳过前几帧，确保摄像头稳定，避免由于启动时摄像头状态不稳定产生错误
sensor.set_auto_gain(False)  # 关闭自动增益，确保颜色跟踪不受环境光影响，避免图像质量变化
sensor.set_auto_whitebal(False)  # 关闭自动白平衡，确保颜色跟踪不受环境光和白平衡影响
clock = time.clock()  # 创建一个 clock 对象，用于计算帧率 (FPS)，帮助评估性能


#以上是初始化代码


#以下是执行代码


#运行监测
led = pyb.LED(1) # led = pyb.LED(1)表示led表示红灯。各种状态如下:Red LED = 1, Green LED = 2, Blue LED = 3, IR LEDs = 4.
led.on()         #点亮红灯 板载红灯点亮表示程序得到执行





#以下是必要的
while True:
    clock.tick()  # 计时一帧的处理时间，帮助计算帧率（FPS）
    img = sensor.snapshot()  # 捕获当前帧图像，获取实时的摄像头图像

#以上是必要的
    print("FPS %f" % clock.fps())   # 打印当前帧率（每秒帧数），便于调试性能
    
    

```



#识别颜色（红色）

```python

color_threshold = (30, 100, 15, 127, 15, 127)  # 红色的色彩空间阈值，可以根据需要调整阈值范围

while True: 
# 使用 find_blobs 查找颜色区域，返回符合条件的 blob  
 # 这里使用了上面定义的红色阈值，根据阈值对图像进行颜色区域检测
    for blob in img.find_blobs(
        [color_threshold],  # 使用当前定义的颜色阈值进行颜色跟踪，目标为红色区域
        pixels_threshold=200,  # 过滤掉小的 blob，最小像素数为 200。较小的区域可能不值得跟踪
        area_threshold=200,  # 过滤掉面积过小的区域，较小的区域通常不被认为是有效的目标
        merge=True,  # 合并重叠的 blob（如果多个检测到的区域重叠，它们会被合并为一个）
    ):
        # 对于延伸性较强的区域（非圆形区域），进行边缘和轴线的绘制
        if blob.elongation() > 0.5:  # 如果区域的延伸性大于 0.5（接近矩形），则认为其为较为规则的区域
            img.draw_edges(blob.min_corners(), color=(255, 0, 0))  # 绘制区域的最小矩形边缘，使用红色进行标记
            img.draw_line(blob.major_axis_line(), color=(0, 255, 0))  # 绘制主轴线，使用绿色进行标记
            img.draw_line(blob.minor_axis_line(), color=(0, 0, 255))  # 绘制副轴线，使用蓝色进行标记
            
        else :  # 这是blob.elongation() 小于等于0.5是圆形或者正方形了
            # 绘制圆形
            # 使用宽度和高度中的较小值来作为圆形的半径
            radius = int(min(blob.w(), blob.h()) / 2)  # 计算半径，选择宽度和高度中的较小值作为半径
            img.draw_circle(blob.cx(), blob.cy(), radius, color=(255, 0, 0))  # 绘制红色圆形
            
            print("Circle found: x = {}, y = {}, radius = {}, ".format(blob.cx(), blob.cy(), radius))
            
        img.draw_cross(blob.cx(), blob.cy())  # 绘制中心交叉十字，表示颜色区域的中心位置
```



### 睿康代码

```python
import sensor, image, time, math, display
from pyb import UART
from pyb import LED

led =LED(2)

# 定义多种颜色的阈值
color_thresholds = [
    ((0, 100, 20, 127, 127, -10), 'red', (255, 165, 0)),  # 红色阈值
    ((30, 100, -64, -8, -32, 32), 'green', (0, 255, 255)),  # 绿色阈值
]

# 初始化摄像头和LCD
sensor.reset()
sensor.set_pixformat(sensor.RGB565)
sensor.set_framesize(sensor.QQVGA)  # 适配LCD屏幕大小128x160
lcd = display.SPIDisplay()
clock = time.clock()
area_threshold = 500  # 设置面积阈值
K = 1150  # 初始K值
last_print_time = time.time()  # 记录上一次打印的时间
uart = UART(3, 115200, timeout_char=1000)  # 初始化串口通信
length = 0  # 给length一个默认值，以防没有任何色块被检测到
while True:
    
    led.on()
    clock.tick()
    img = sensor.snapshot()  # 拍照
    selected_blob = None
    selected_blob_pixels = 0
    min_length = float('inf')
    color_code = 0  # 每次循环迭代开始时重新初始化颜色代码为0（未检测到）
    display_text = "未检测到色块"  # 初始化显示文本
    uart_data_display = ""  # 初始化串口数据显示文本

    # 多颜色识别
    for threshold, color_name, frame_color in color_thresholds:
        blobs = img.find_blobs([threshold], pixels_threshold=100, area_threshold=area_threshold, merge=True)
        for blob in blobs:
            if blob.pixels() >= area_threshold:
                b = blob.rect()
                img.draw_rectangle(b, color=frame_color)
                img.draw_cross(blob.cx(), blob.cy())
                Lm = (b[2] + b[3]) / 2
                length = K / Lm
                if (color_name == 'red' and (length < min_length or not selected_blob)) or (color_name == 'green' and not selected_blob and length < min_length):
                    selected_blob = (blob, frame_color, color_name, length)
                    selected_blob_pixels = blob.pixels()
                    min_length = length
                    color_code = 1 if color_name == 'red' else 2
                    display_text = f"Color: {color_name}\nDistance: {length:.2f} \nX={blob.cx()}, Y={blob.cy()}\nArea: {selected_blob_pixels}"

    # 检查是否有选中的色块
    if selected_blob:
        blob, frame_color, color_name, length = selected_blob
        b = blob.rect()
        img.draw_rectangle(b, color=(255, 0, 0), thickness=2)  # 使用红色框突出显示
        img.draw_cross(blob.cx(), blob.cy())

        # 构建并发送数据
        x4 = blob.cx() // 256
        num_x = blob.cx() % 256
        num_y = blob.cy()
        img_data = bytearray([0x2C, 18, num_x, x4, num_y, color_code, 0x5B])  # 构建数据包
        uart.write(img_data)  # 通过串口发送数据
        uart_data_display = "UART: " + " ".join(["{:02x}".format(x) for x in img_data])
    else:
        # 如果没有检测到色块，发送默认数据
        img_data = bytearray([0x2C, 18, 0, 0, 0, 0, 0x5B])
        uart.write(img_data)
        uart_data_display = "UART: " + " ".join(["{:02x}".format(x) for x in img_data])

    # 显示结果
    if time.time() - last_print_time > 0.4:
        print(display_text)
        last_print_time = time.time()
    
    img.draw_string(2, 2, display_text, color=(0,0,255), scale=1, mono_space=False)  # 在图像左上角显示识别结果文本
    img.draw_string(2, 150, uart_data_display, color=(255,255,255), scale=1, mono_space=False)  # 显示串口数据
    lcd.write(img)  # 显示图像和文本
```







